{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories names and {len(filenames)} images in '{dir_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(r'D:\\Sem 3\\DL\\Classification\\data')\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "image_path_list = list(image_path.glob(\"**/*.png\"))\n",
    "\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn the image into an array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape}\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform(img).shape, data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths: list, transform, n=3, seed=None):\n",
    "    # Select random images from a path of images and loads/transforms them then plots the original vs the transformed version.\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"original\\nsize: {f.size}\")\n",
    "            \n",
    "            # Transform and plot target image\n",
    "            transformed_image = transform(f).permute(1, 2, 0)  # note we will need to change shape for matplotlib\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "            fig.suptitle(f\"class: {image_path.parent.stem}\", fontsize=16)\n",
    "            \n",
    "plot_transformed_images(image_paths=image_path_list,\n",
    "                        transform=data_transform,\n",
    "                        n=3,\n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(r'D:\\Sem 3\\DL\\Classification\\data\\train')\n",
    "val_dir = Path(r'D:\\Sem 3\\DL\\Classification\\data\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = datasets.ImageFolder(root=train_dir,\n",
    "#                                   transform=data_transform,\n",
    "#                                   target_transform=None)\n",
    "\n",
    "# val_data = datasets.ImageFolder(root=val_dir,\n",
    "#                                 transform=data_transform)\n",
    "\n",
    "# train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = train_dir\n",
    "print(f\"Target dir: {target_directory}\")\n",
    "\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
    "class_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "     \n",
    "    # 2. Raise an error if class names not found\n",
    "    # if not classes:\n",
    "    #     raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "    \n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChristmasImages(Dataset):\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"**/*.png\"))\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "    \n",
    "    #  Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        # dummy_label = 0  # Use a dummy label since there are no classes\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx\n",
    "        else:\n",
    "            return img, class_idx    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_three_channels(image):\n",
    "    if image.size(0) == 1:  # Grayscale to RGB\n",
    "        image = image.expand(3, -1, -1)\n",
    "    elif image.size(0) == 2:  # Duplicate the two channels to make it 3 channels\n",
    "        image = torch.cat([image, image[:1, :, :]], dim=0)\n",
    "    elif image.size(0) == 4:  # RGBA to RGB by discarding the alpha channel\n",
    "        image = image[:3, :, :]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize(size=(128,128)),\n",
    "                                       transforms.CenterCrop(128),\n",
    "                                       # transforms.RandomRotation(degrees=(-180, 180)),\n",
    "                                       # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Lambda(ensure_three_channels),\n",
    "                                    #    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "val_transforms = transforms.Compose([transforms.Resize(size=(128, 128)),\n",
    "                                    transforms.CenterCrop(128),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Lambda(ensure_three_channels),\n",
    "                                    # transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ChristmasImages(targ_dir=train_dir,\n",
    "                             transform=train_transforms)\n",
    "val_data = ChristmasImages(targ_dir=val_dir,\n",
    "                           transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class name as list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(dataset: torch.utils.data.Dataset,\n",
    "                          classes: List[str] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None):\n",
    "    # Adjust display if n is too high\n",
    "    if n > 10:\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10.\")\n",
    "        \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Get the random sample indexes\n",
    "    random_sample_idx = random.sample(range(len(dataset)), k=n)\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    \n",
    "    # Loop through random indexex and plot them with matplotlib\n",
    "    for i, targ_sample in enumerate(random_sample_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "        \n",
    "        # Adjust tensor dimensions for plotting\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)   # [c, h, w] -> [h, w, c]\n",
    "        \n",
    "        # plot adjusted sample\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(False)\n",
    "        if classes:\n",
    "            title = f\"Class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(dataset=train_data,\n",
    "                      classes=class_names,\n",
    "                      n=5,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False)\n",
    "train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and label fromdataloader\n",
    "img_custom, label_custom = next(iter(train_dataloader))\n",
    "img_custom.shape, label_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image paths\n",
    "image_path_list = list(image_path.glob(\"**/*.png\"))\n",
    "image_path_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transformed_images(image_paths=image_path_list,\n",
    "                        transform=train_transforms,\n",
    "                        n=3,\n",
    "                        seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "                      ),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*8*8,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_3(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_4(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model_0 = Network(input_shape=3,\n",
    "                  hidden_units=20,\n",
    "                  output_shape=len(train_data.classes)).cuda()\n",
    "\n",
    "model_0.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "image_single, label_single = image_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {image_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(image_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try forward pass\n",
    "# model_0(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model_0, input_size=[1,3,128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch, (X, y) in enumerate(train_dataloader):\n",
    "#     print(f\"Batch {batch}: X.shape = {X.shape}\")\n",
    "#     # Check if all X in batch have 3 channels\n",
    "#     assert all(x.shape[0] == 3 for x in X), f\"Found X with channels not equal to 3 in batch {batch}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "# def accuracy_fn(y_pred, y):\n",
    "#     acc = (y_pred.argmax(dim=1) == y).float().mean()\n",
    "#     return acc.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accurucy_fn,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    \n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1)\n",
    "                                    # y_pred=test_pred\n",
    "                                    )\n",
    "\n",
    "            # Example adjustment (assuming you want to accumulate some kind of metrics):\n",
    "            # test_loss += loss_fn(test_pred, X).item()  # Using X as a placeholder for true labels\n",
    "            # test_accuracy += accuracy_fn(test_pred, X).item()  # Using X as a placeholder for true labels\n",
    "            \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time: .3f} secs\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)   # Don't use random seed while training\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_model_0 = timer()\n",
    "\n",
    "# Train and test model\n",
    "epochs = 30\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n----\")\n",
    "    train_step(model=model_0,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accurucy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    \n",
    "    test_step(model=model_0,\n",
    "              data_loader=val_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "train_time_end_model_0 = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_model_0,\n",
    "                                            end=train_time_end_model_0,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true = y,\n",
    "                               y_pred = y_pred.argmax(dim=1))\n",
    "            \n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "    \n",
    "model_0_results = eval_model(model=model_0,\n",
    "                             data_loader=val_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data: list):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            sample = torch.unsqueeze(sample, dim=0)\n",
    "            \n",
    "            pred_logits = model(sample)\n",
    "            \n",
    "            pred_prob = torch.softmax(pred_probs.squeeze(), dim=0)\n",
    "            pred_probs.append(pred_prob)\n",
    "    \n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
